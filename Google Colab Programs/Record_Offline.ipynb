{"cells":[{"cell_type":"markdown","metadata":{"id":"Wv2qhEIMX6Rp"},"source":["# Initial"]},{"cell_type":"markdown","metadata":{"id":"ByUo4uJQ6aVh"},"source":["## Imports:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6iNyTD8WByc8"},"outputs":[],"source":["# Standard Library Imports\n","import os\n","import pickle\n","import shutil\n","import time\n","import asyncio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10381,"status":"ok","timestamp":1696507672437,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"},"user_tz":-330},"id":"SX3Uj9ZECRDA","outputId":"5caffdba-4adf-4805-c78c-2def0e43a665"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting fastapi\n","  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m61.4/66.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.7.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi)\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.5.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.1.3)\n","Installing collected packages: starlette, fastapi\n","Successfully installed fastapi-0.103.2 starlette-0.27.0\n"]}],"source":["!pip install fastapi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csqsJEoyCOfj"},"outputs":[],"source":["# Third-party Library Imports\n","import concurrent.futures\n","from concurrent.futures import ThreadPoolExecutor\n","import cv2\n","import numpy as np\n","from fastapi import FastAPI, HTTPException\n","from fastapi.responses import HTMLResponse, RedirectResponse\n","from multiprocessing import Pool\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2051,"status":"ok","timestamp":1696507674455,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"},"user_tz":-330},"id":"YsU3okzJCfAK","outputId":"7350a4eb-285d-41d9-f02c-7419d1149ed2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting deepface\n","  Downloading deepface-0.0.79-py3-none-any.whl (49 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.23.5)\n","Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.5.3)\n","Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.66.1)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.6.6)\n","Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (9.4.0)\n","Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.8.0.76)\n","Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.13.0)\n","Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.13.1)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.5)\n","Collecting mtcnn>=0.1.0 (from deepface)\n","  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting retina-face>=0.0.1 (from deepface)\n","  Downloading retina_face-0.0.13-py3-none-any.whl (16 kB)\n","Collecting fire>=0.4.0 (from deepface)\n","  Downloading fire-0.5.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gunicorn>=20.1.0 (from deepface)\n","  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.3.0)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.3.7)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.2)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.12.4)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (2.31.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.11.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (23.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2023.3.post1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.58.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (16.0.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (67.7.2)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.13.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.34.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.41.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface) (3.4.4)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface) (0.7.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2023.7.22)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface) (1.3.1)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface) (3.2.2)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=ce28ddcd51db5577268ec86e7f61848e5965248ff1e3d5756cd74dd16807ee6e\n","  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n","Successfully built fire\n","Installing collected packages: gunicorn, fire, mtcnn, retina-face, deepface\n","Successfully installed deepface-0.0.79 fire-0.5.0 gunicorn-21.2.0 mtcnn-0.1.1 retina-face-0.0.13\n"]}],"source":["pip install deepface"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5472,"status":"ok","timestamp":1696507679923,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"},"user_tz":-330},"id":"r2ZfCZC0CfF8","outputId":"1b9d069e-aa4f-4aa0-e6f8-4e4d6efa959c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory  /root /.deepface created\n","Directory  /root /.deepface/weights created\n"]}],"source":["# Deep Learning Model Imports\n","from deepface import DeepFace as dpf\n","from deepface.commons import functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":740,"status":"ok","timestamp":1696507680616,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"},"user_tz":-330},"id":"4cIwCMqWClPb","outputId":"07689dad-2631-4a23-c311-106fab69bb4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting retinaface\n","  Downloading retinaface-1.1.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of retinaface to determine which version is compatible with other requirements. This could take a while.\n","  Downloading retinaface-1.1.0-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading retinaface-0.0.6-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading retinaface-0.0.5-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading retinaface-0.0.4-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading retinaface-0.0.3-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading retinaface-0.0.2-py3-none-any.whl (7.5 kB)\n","  Downloading retinaface-0.0.1-py3-none-any.whl (7.5 kB)\n","INFO: pip is looking at multiple versions of retinaface to determine which version is compatible with other requirements. This could take a while.\n","\u001b[31mERROR: Cannot install retinaface==0.0.1, retinaface==0.0.2, retinaface==0.0.3, retinaface==0.0.4, retinaface==0.0.5, retinaface==0.0.6, retinaface==1.1.0 and retinaface==1.1.1 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n","\u001b[0m\n","The conflict is caused by:\n","    retinaface 1.1.1 depends on tensorflow==2.5.0\n","    retinaface 1.1.0 depends on tensorflow==2.5.0\n","    retinaface 0.0.6 depends on tensorflow==2.1.0\n","    retinaface 0.0.5 depends on tensorflow==2.1.0\n","    retinaface 0.0.4 depends on tensorflow==2.1.0\n","    retinaface 0.0.3 depends on tensorflow==2.1.0\n","    retinaface 0.0.2 depends on tensorflow==2.1.0\n","    retinaface 0.0.1 depends on tensorflow==2.1.0\n","\n","To fix this you could try to:\n","1. loosen the range of package versions you've specified\n","2. remove package versions to allow pip attempt to solve the dependency conflict\n","\n","\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["pip install retinaface"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jABxAF7CkZc"},"outputs":[],"source":["# Computer Vision Model Imports\n","from retinaface import RetinaFace"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"yc1RGSkmDvr-","outputId":"71542a38-8232-4bdc-b0ba-b0809bf7e132"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting uvicorn\n","  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.5.0)\n","Installing collected packages: h11, uvicorn\n","Successfully installed h11-0.14.0 uvicorn-0.23.2\n"]}],"source":["pip install uvicorn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8_7KhOQvDyGb"},"outputs":[],"source":["import uvicorn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6PX5zFDJyxAd"},"outputs":[],"source":["# Visualization\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yM3vXKEOA2OI"},"outputs":[],"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time"]},{"cell_type":"markdown","metadata":{"id":"L6pCmkJrUC9g"},"source":["## Helper Functions\n","Below are a few helper function to make converting between different image data types and formats."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"09b_0FAnUa9y"},"outputs":[],"source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"]},{"cell_type":"markdown","metadata":{"id":"MaZIOR4WaT64"},"source":["## Haar Cascade Classifier\n","For this tutorial we will run a simple object detection algorithm called Haar Cascade on our images and video fetched from our webcam. OpenCV has a pre-trained Haar Cascade face detection model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZpA68lTrcvZs"},"outputs":[],"source":["# initialize the Haar Cascade face detection model\n","face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"]},{"cell_type":"markdown","metadata":{"id":"ApNbx9mX7AQs"},"source":["## API Object:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mXfOpOS_Cu4P"},"outputs":[],"source":["# Creating the fastapi object\n","app = FastAPI()"]},{"cell_type":"markdown","metadata":{"id":"XElxKu9M7DXd"},"source":["## Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_7U87HHGC5RY"},"outputs":[],"source":["# Constants\n","FACE_MAX_WORKERS = 14\n","PKL_MAX_WORKERS = 16\n","RECORDING_OUTPUT = \"Frames\"\n","FACE_OUTPUT = \"Data\"\n","FACE_THRESHOLD = 0.99\n","FPS = 30\n","CAMERA_INDEX = 0\n","DIRECTORY = os.getcwd()"]},{"cell_type":"markdown","metadata":{"id":"AIYbi_aY7HIk"},"source":["## Functions"]},{"cell_type":"markdown","metadata":{"id":"1fXA8PJEeFLB"},"source":["### Processing Image Function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PoLlwMMmC6i9"},"outputs":[],"source":["def process_image(employee):\n","    model_name = \"VGG-Face\"\n","    enforce_detection = False\n","    detector_backend = \"retinaface\"\n","    align = True\n","    normalization = \"base\"\n","\n","    target_size = functions.find_target_size(model_name=model_name)\n","\n","    img_objs = functions.extract_faces(img=employee, target_size=target_size, detector_backend=detector_backend, grayscale=False, enforce_detection=enforce_detection, align=align)\n","    representations = []\n","    for img_content, _, _ in img_objs:\n","        embedding_obj = Deep.represent(img_path=img_content, model_name=model_name, enforce_detection=enforce_detection, detector_backend=\"skip\", align=align, normalization=normalization)\n","        img_representation = embedding_obj[0][\"embedding\"]\n","        instance = [employee, img_representation]\n","        representations.append(instance)\n","    return representations"]},{"cell_type":"markdown","metadata":{"id":"rxx2MDPWeJzQ"},"source":["### Taking Photo Function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XwUtEojjnPRb"},"outputs":[],"source":["def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","\n","  # get photo data\n","  data = eval_js('takePhoto({})'.format(quality))\n","  # get OpenCV format image\n","  img = js_to_image(data)\n","  # save image\n","  cv2.imwrite(filename, img)\n","\n","  return filename"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KjPfkNmeBGNR"},"outputs":[],"source":["class GoogleWebcam:\n","  def generate_filename(self, count):\n","        return f'Frame {count:02d}.jpg'\n","\n","  def record_video(self,frames):\n","        frames_dir = os.path.join(DIRECTORY, RECORDING_OUTPUT)\n","        os.makedirs(frames_dir, exist_ok=True)\n","        count = -1\n","\n","        while True:\n","            count += 1\n","            filename = os.path.join(frames_dir, self.generate_filename(count))\n","\n","            take_photo(filename)\n","\n","            print(filename)\n","\n","            if count > frames:\n","                break\n","\n","  def cam(self,filename):\n","    try:\n","      print('Saved to {}'.format(filename))\n","\n","      # Show the image which was just taken.\n","      display(Image(filename))\n","    except Exception as err:\n","      print(str(err))"]},{"cell_type":"markdown","metadata":{"id":"HEYg2oumeM66"},"source":["### Taking photos from webcam normally"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mrsnyKBPDACm"},"outputs":[],"source":["class FaceExtractor:\n","    def process_frame(self, filename):\n","        try:\n","            count = os.path.split(filename)[1].split(' ')[1].split('.')[0]\n","            filename1 = os.path.join(os.path.join(DIRECTORY, RECORDING_OUTPUT), filename)\n","\n","            faces = RetinaFace.extract_faces(filename1, threshold=FACE_THRESHOLD, model=None, allow_upscaling=True)\n","\n","            if not faces:\n","                print(f\"No faces extracted in Frame {count}.\")\n","                return None\n","\n","            path0 = os.path.join(DIRECTORY, FACE_OUTPUT)\n","            if not os.path.exists(path0):\n","                os.makedirs(path0)\n","\n","            id = 1\n","\n","            image_sizes = [np.prod(image.shape) for image in faces]\n","            largest_index = np.argmax(image_sizes)\n","            filename2 = f\"user.{id}.{count}.jpg\"\n","            result = os.path.join(path0, filename2)\n","            print(f\"user.1.{count}.jpg written\")\n","            cv2.imwrite(result, faces[largest_index])\n","\n","            return count\n","\n","        except Exception as e:\n","            print(str(e))\n","            return None\n","\n","    async def video_to_faces_parallel(self):\n","        os.chdir(DIRECTORY)\n","        if os.path.exists(RECORDING_OUTPUT):\n","            files = os.listdir(os.path.join(DIRECTORY, RECORDING_OUTPUT))\n","\n","            with concurrent.futures.ThreadPoolExecutor(max_workers=FACE_MAX_WORKERS) as executor:\n","                futures = [executor.submit(self.process_frame, filename) for filename in files]\n","                concurrent.futures.wait(futures)\n","        else:\n","            print(\"No photos folder found.\")"]},{"cell_type":"markdown","metadata":{"id":"_4T3MCmreTTp"},"source":["###Cleaning Function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"O7kd0K72DCPm"},"outputs":[],"source":["class Cleanup:\n","    @staticmethod\n","    def clean():\n","        directory_path = os.path.join(DIRECTORY, RECORDING_OUTPUT)\n","        try:\n","            shutil.rmtree(directory_path)\n","            print(f'Directory \"{directory_path}\" and its contents have been successfully deleted.')\n","        except Exception as e:\n","            print(f'An error occurred: {e}')"]},{"cell_type":"markdown","metadata":{"id":"Kkc6d7HYeVf0"},"source":["### Pkl FIle Making Function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hCEoVRJ3DEju"},"outputs":[],"source":["class Deep:\n","    @staticmethod\n","    def represent(img_path, model_name=\"VGG-Face\", enforce_detection=False, detector_backend=\"retinaface\", align=True,\n","                  normalization=\"base\"):\n","        resp_objs = []\n","        model = dpf.build_model(model_name)\n","\n","        target_size = functions.find_target_size(model_name=model_name)\n","        if detector_backend != \"skip\":\n","            img_objs = functions.extract_faces(img=img_path, target_size=target_size, detector_backend=detector_backend,\n","                                               grayscale=False, enforce_detection=enforce_detection, align=align)\n","        else:\n","            if isinstance(img_path, str):\n","                img = functions.load_image(img_path)\n","            elif type(img_path).__module__ == np.__name__:\n","                img = img_path.copy()\n","            else:\n","                raise ValueError(f\"unexpected type for img_path - {type(img_path)}\")\n","\n","            if len(img.shape) == 4:\n","                img = img[0]\n","            if len(img.shape) == 3:\n","                img = cv2.resize(img, target_size)\n","                img = np.expand_dims(img, axis=0)\n","\n","            img_region = [0, 0, img.shape[1], img.shape[0]]\n","            img_objs = [(img, img_region, 0)]\n","\n","        for img, region, _ in img_objs:\n","            img = functions.normalize_input(img=img, normalization=normalization)\n","\n","            if \"keras\" in str(type(model)):\n","                embedding = model.predict(img, verbose=0)[0].tolist()\n","            else:\n","                embedding = model.predict(img)[0].tolist()\n","\n","            resp_obj = {\"embedding\": embedding, \"facial_area\": region}\n","            resp_objs.append(resp_obj)\n","\n","        return resp_objs\n","\n","    def create_pkl_multiprocessing(self):\n","\n","        tik = time.time()\n","\n","        db_path = FACE_OUTPUT\n","        model_name = \"VGG-Face\"\n","        enforce_detection = False\n","        detector_backend = \"retinaface\"\n","        align = True\n","        normalization = \"base\"\n","        silent = False\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","\n","        pkl = f\"{db_path}/{file_name}\"\n","\n","        if os.path.exists(pkl):\n","            os.remove(pkl)\n","\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if ((\".jpg\" in file.lower()) or (\".jpeg\" in file.lower()) or (\".png\" in file.lower())):\n","                    exact_path = os.path.join(r, file)\n","                    employees.append(exact_path)\n","\n","        if len(employees) == 0:\n","            raise ValueError(\"There is no image in \", db_path, \" folder! Validate .jpg or .png files exist in this path.\")\n","\n","        representations = []\n","\n","        MAX_WORKERS = 6\n","\n","        with Pool(MAX_WORKERS) as pool:\n","            for batch_start in range(0, len(employees), MAX_WORKERS):\n","                batch_employees = employees[batch_start:batch_start + MAX_WORKERS]\n","                representations_list = list(tqdm(pool.imap(process_image, batch_employees), total=len(batch_employees), desc=\"Finding representations\", disable=silent))\n","                representations.extend([item for sublist in representations_list for item in sublist])\n","\n","        with open(pkl, \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(f\"Representations stored in {db_path}/{file_name}. Please delete this file when you add new identities in your database.\")\n","\n","        tok = time.time()\n","\n","        print(\"Multiprocessing: \",str(round(tok-tik)))\n","\n","    def create_pkl_nonopti(self):\n","\n","        tik = time.time()\n","\n","        db_path = FACE_OUTPUT\n","        model_name = \"VGG-Face\"\n","        enforce_detection = False\n","        detector_backend = \"retinaface\"\n","        align = True\n","        normalization = \"base\"\n","        silent = False\n","        target_size = functions.find_target_size(model_name=model_name)\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","\n","        pkl = f\"{db_path}/{file_name}\"\n","\n","\n","        if os.path.exists(pkl):\n","            os.remove(pkl)\n","\n","\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if (\n","                    (\".jpg\" in file.lower())\n","                    or (\".jpeg\" in file.lower())\n","                    or (\".png\" in file.lower())\n","                ):\n","                    exact_path = r + \"/\" + file\n","                    employees.append(exact_path)\n","\n","        if len(employees) == 0:\n","            raise ValueError(\n","                \"There is no image in \",\n","                db_path,\n","                \" folder! Validate .jpg or .png files exist in this path.\",\n","            )\n","\n","        # ------------------------\n","        # find representations for db images\n","\n","        representations = []\n","\n","        # for employee in employees:\n","        pbar = tqdm(\n","            range(0, len(employees)),\n","            desc=\"Finding representations\",\n","            disable=silent,\n","        )\n","        for index in pbar:\n","            employee = employees[index]\n","\n","            img_objs = functions.extract_faces(\n","                img=employee,\n","                target_size=target_size,\n","                detector_backend=detector_backend,\n","                grayscale=False,\n","                enforce_detection=enforce_detection,\n","                align=align,\n","            )\n","\n","            for img_content, _, _ in img_objs:\n","                embedding_obj = self.represent(\n","                    img_path=img_content,\n","                    model_name=model_name,\n","                    enforce_detection=enforce_detection,\n","                    detector_backend=\"skip\",\n","                    align=align,\n","                    normalization=normalization,\n","                )\n","\n","                img_representation = embedding_obj[0][\"embedding\"]\n","\n","                instance = []\n","                instance.append(employee)\n","                instance.append(img_representation)\n","                representations.append(instance)\n","\n","        # -------------------------------\n","\n","        with open(f\"{db_path}/{file_name}\", \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(\n","                f\"Representations stored in {db_path}/{file_name} file.\"\n","                + \"Please delete this file when you add new identities in your database.\"\n","            )\n","\n","        tok = time.time()\n","\n","        print(\"Non Optimized: \",str(round(tok-tik)))\n","\n","    def create_pkl_concurrent(self):\n","\n","        tik = time.time()\n","\n","        db_path = FACE_OUTPUT\n","        model_name = \"VGG-Face\"\n","        enforce_detection = False\n","        detector_backend = \"retinaface\"\n","        align = True\n","        normalization = \"base\"\n","        silent = False\n","        target_size = functions.find_target_size(model_name=model_name)\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","\n","        print(file_name)\n","\n","\n","        pkl = f\"{db_path}/{file_name}\"\n","\n","        if os.path.exists(pkl):\n","            os.remove(pkl)\n","\n","        print(pkl)\n","\n","        # Create a tqdm progress bar object\n","        progress_bar = tqdm(total=(len(os.listdir(os.path.join(DIRECTORY,FACE_OUTPUT)))), desc=\"Processing\", unit=\" items\")\n","\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if (\".jpg\" in file.lower()) or (\".jpeg\" in file.lower()) or (\".png\" in file.lower()):\n","                    exact_path = r + \"/\" + file\n","                    employees.append(exact_path)\n","\n","        if len(employees) == 0:\n","            raise ValueError( \"There is no image in \", db_path, \" folder! Validate .jpg or .png files exist in this path\")\n","\n","        representations = []\n","\n","        global count\n","        count = 0\n","\n","        def process_employee(employee):\n","            img_objs = functions.extract_faces( img=employee, target_size=target_size, detector_backend=detector_backend, grayscale=False, enforce_detection=enforce_detection, align=align, )\n","\n","            for img_content, _, _ in img_objs:\n","                embedding_obj = self.represent( img_path=img_content, model_name=model_name, enforce_detection=enforce_detection, detector_backend=\"skip\", align=align, normalization=normalization, )\n","\n","                img_representation = embedding_obj[0][\"embedding\"]\n","\n","                instance = []\n","                instance.append(employee)\n","                instance.append(img_representation)\n","                representations.append(instance)\n","                global count\n","                count += 1\n","                # print(count)\n","                progress_bar.update(1)\n","\n","\n","        # Create a ThreadPoolExecutor\n","        max_workers = PKL_MAX_WORKERS\n","        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n","            list(executor.map(process_employee, employees))\n","\n","        with open(f\"{db_path}/{file_name}\", \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(\n","                f\"Representations stored in {db_path}/{file_name} file.\"\n","                + \"Please delete this file when you add new identities in your database.\"\n","            )\n","\n","        # Close the progress bar\n","        progress_bar.close()\n","\n","        tok = time.time()\n","\n","        print(\"Concurrent Futures: \",str(round(tok-tik)))"]},{"cell_type":"markdown","metadata":{"id":"sYvYpizr7LKe"},"source":["# Main Play Area"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCFjY1Pv0Ky8"},"outputs":[],"source":["webcam = GoogleWebcam()\n","webcam.record_video(frames=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"E9oStjTjHEJH"},"outputs":[],"source":["face_extractor = FaceExtractor()\n","await face_extractor.video_to_faces_parallel()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fNHKGwDnHEh1"},"outputs":[],"source":["# cle = Cleanup()\n","# cle.clean()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"U85NcTfyHQTg"},"outputs":[],"source":["dp = Deep()\n","dp.create_pkl_concurrent()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["ByUo4uJQ6aVh","L6pCmkJrUC9g","MaZIOR4WaT64","AIYbi_aY7HIk"],"provenance":[],"authorship_tag":"ABX9TyPLC7XEAnmx9zkS6q1arHyl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}