{"cells":[{"cell_type":"markdown","metadata":{"id":"Wv2qhEIMX6Rp"},"source":["# Initial"]},{"cell_type":"markdown","metadata":{"id":"ByUo4uJQ6aVh"},"source":["## Imports:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6iNyTD8WByc8"},"outputs":[],"source":["# Standard Library Imports\n","import os\n","import pickle\n","import shutil\n","import time\n","import asyncio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10381,"status":"ok","timestamp":1696507672437,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"},"user_tz":-330},"id":"SX3Uj9ZECRDA","outputId":"5caffdba-4adf-4805-c78c-2def0e43a665"},"outputs":[],"source":["!pip install fastapi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csqsJEoyCOfj"},"outputs":[],"source":["# Third-party Library Imports\n","import concurrent.futures\n","from concurrent.futures import ThreadPoolExecutor\n","import cv2\n","import numpy as np\n","from fastapi import FastAPI, HTTPException\n","from fastapi.responses import HTMLResponse, RedirectResponse\n","from multiprocessing import Pool\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2051,"status":"ok","timestamp":1696507674455,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"},"user_tz":-330},"id":"YsU3okzJCfAK","outputId":"7350a4eb-285d-41d9-f02c-7419d1149ed2"},"outputs":[],"source":["pip install deepface"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5472,"status":"ok","timestamp":1696507679923,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"},"user_tz":-330},"id":"r2ZfCZC0CfF8","outputId":"1b9d069e-aa4f-4aa0-e6f8-4e4d6efa959c"},"outputs":[],"source":["# Deep Learning Model Imports\n","from deepface import DeepFace as dpf\n","from deepface.commons import functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":740,"status":"ok","timestamp":1696507680616,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"},"user_tz":-330},"id":"4cIwCMqWClPb","outputId":"07689dad-2631-4a23-c311-106fab69bb4d"},"outputs":[],"source":["pip install retinaface"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jABxAF7CkZc"},"outputs":[],"source":["# Computer Vision Model Imports\n","from retinaface import RetinaFace"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"yc1RGSkmDvr-","outputId":"71542a38-8232-4bdc-b0ba-b0809bf7e132"},"outputs":[],"source":["pip install uvicorn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8_7KhOQvDyGb"},"outputs":[],"source":["import uvicorn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6PX5zFDJyxAd"},"outputs":[],"source":["# Visualization\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yM3vXKEOA2OI"},"outputs":[],"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time"]},{"cell_type":"markdown","metadata":{"id":"L6pCmkJrUC9g"},"source":["## Helper Functions\n","Below are a few helper function to make converting between different image data types and formats."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"09b_0FAnUa9y"},"outputs":[],"source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"]},{"cell_type":"markdown","metadata":{"id":"MaZIOR4WaT64"},"source":["## Haar Cascade Classifier\n","For this tutorial we will run a simple object detection algorithm called Haar Cascade on our images and video fetched from our webcam. OpenCV has a pre-trained Haar Cascade face detection model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZpA68lTrcvZs"},"outputs":[],"source":["# initialize the Haar Cascade face detection model\n","face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"]},{"cell_type":"markdown","metadata":{"id":"ApNbx9mX7AQs"},"source":["## API Object:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mXfOpOS_Cu4P"},"outputs":[],"source":["# Creating the fastapi object\n","app = FastAPI()"]},{"cell_type":"markdown","metadata":{"id":"XElxKu9M7DXd"},"source":["## Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_7U87HHGC5RY"},"outputs":[],"source":["# Constants\n","FACE_MAX_WORKERS = 14\n","PKL_MAX_WORKERS = 16\n","RECORDING_OUTPUT = \"Frames\"\n","FACE_OUTPUT = \"Data\"\n","FACE_THRESHOLD = 0.99\n","FPS = 30\n","CAMERA_INDEX = 0\n","DIRECTORY = os.getcwd()"]},{"cell_type":"markdown","metadata":{"id":"AIYbi_aY7HIk"},"source":["## Functions"]},{"cell_type":"markdown","metadata":{"id":"1fXA8PJEeFLB"},"source":["### Processing Image Function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PoLlwMMmC6i9"},"outputs":[],"source":["def process_image(employee):\n","    model_name = \"VGG-Face\"\n","    enforce_detection = False\n","    detector_backend = \"retinaface\"\n","    align = True\n","    normalization = \"base\"\n","\n","    target_size = functions.find_target_size(model_name=model_name)\n","\n","    img_objs = functions.extract_faces(img=employee, target_size=target_size, detector_backend=detector_backend, grayscale=False, enforce_detection=enforce_detection, align=align)\n","    representations = []\n","    for img_content, _, _ in img_objs:\n","        embedding_obj = Deep.represent(img_path=img_content, model_name=model_name, enforce_detection=enforce_detection, detector_backend=\"skip\", align=align, normalization=normalization)\n","        img_representation = embedding_obj[0][\"embedding\"]\n","        instance = [employee, img_representation]\n","        representations.append(instance)\n","    return representations"]},{"cell_type":"markdown","metadata":{"id":"rxx2MDPWeJzQ"},"source":["### Taking Photo Function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XwUtEojjnPRb"},"outputs":[],"source":["def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","\n","  # get photo data\n","  data = eval_js('takePhoto({})'.format(quality))\n","  # get OpenCV format image\n","  img = js_to_image(data)\n","  # save image\n","  cv2.imwrite(filename, img)\n","\n","  return filename"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KjPfkNmeBGNR"},"outputs":[],"source":["class GoogleWebcam:\n","  def generate_filename(self, count):\n","        return f'Frame {count:02d}.jpg'\n","\n","  def record_video(self,frames):\n","        frames_dir = os.path.join(DIRECTORY, RECORDING_OUTPUT)\n","        os.makedirs(frames_dir, exist_ok=True)\n","        count = -1\n","\n","        while True:\n","            count += 1\n","            filename = os.path.join(frames_dir, self.generate_filename(count))\n","\n","            take_photo(filename)\n","\n","            print(filename)\n","\n","            if count > frames:\n","                break\n","\n","  def cam(self,filename):\n","    try:\n","      print('Saved to {}'.format(filename))\n","\n","      # Show the image which was just taken.\n","      display(Image(filename))\n","    except Exception as err:\n","      print(str(err))"]},{"cell_type":"markdown","metadata":{"id":"HEYg2oumeM66"},"source":["### Taking photos from webcam normally"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mrsnyKBPDACm"},"outputs":[],"source":["class FaceExtractor:\n","    def process_frame(self, filename):\n","        try:\n","            count = os.path.split(filename)[1].split(' ')[1].split('.')[0]\n","            filename1 = os.path.join(os.path.join(DIRECTORY, RECORDING_OUTPUT), filename)\n","\n","            faces = RetinaFace.extract_faces(filename1, threshold=FACE_THRESHOLD, model=None, allow_upscaling=True)\n","\n","            if not faces:\n","                print(f\"No faces extracted in Frame {count}.\")\n","                return None\n","\n","            path0 = os.path.join(DIRECTORY, FACE_OUTPUT)\n","            if not os.path.exists(path0):\n","                os.makedirs(path0)\n","\n","            id = 1\n","\n","            image_sizes = [np.prod(image.shape) for image in faces]\n","            largest_index = np.argmax(image_sizes)\n","            filename2 = f\"user.{id}.{count}.jpg\"\n","            result = os.path.join(path0, filename2)\n","            print(f\"user.1.{count}.jpg written\")\n","            cv2.imwrite(result, faces[largest_index])\n","\n","            return count\n","\n","        except Exception as e:\n","            print(str(e))\n","            return None\n","\n","    async def video_to_faces_parallel(self):\n","        os.chdir(DIRECTORY)\n","        if os.path.exists(RECORDING_OUTPUT):\n","            files = os.listdir(os.path.join(DIRECTORY, RECORDING_OUTPUT))\n","\n","            with concurrent.futures.ThreadPoolExecutor(max_workers=FACE_MAX_WORKERS) as executor:\n","                futures = [executor.submit(self.process_frame, filename) for filename in files]\n","                concurrent.futures.wait(futures)\n","        else:\n","            print(\"No photos folder found.\")"]},{"cell_type":"markdown","metadata":{"id":"_4T3MCmreTTp"},"source":["###Cleaning Function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"O7kd0K72DCPm"},"outputs":[],"source":["class Cleanup:\n","    @staticmethod\n","    def clean():\n","        directory_path = os.path.join(DIRECTORY, RECORDING_OUTPUT)\n","        try:\n","            shutil.rmtree(directory_path)\n","            print(f'Directory \"{directory_path}\" and its contents have been successfully deleted.')\n","        except Exception as e:\n","            print(f'An error occurred: {e}')"]},{"cell_type":"markdown","metadata":{"id":"Kkc6d7HYeVf0"},"source":["### Pkl FIle Making Function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hCEoVRJ3DEju"},"outputs":[],"source":["class Deep:\n","    @staticmethod\n","    def represent(img_path, model_name=\"VGG-Face\", enforce_detection=False, detector_backend=\"retinaface\", align=True,\n","                  normalization=\"base\"):\n","        resp_objs = []\n","        model = dpf.build_model(model_name)\n","\n","        target_size = functions.find_target_size(model_name=model_name)\n","        if detector_backend != \"skip\":\n","            img_objs = functions.extract_faces(img=img_path, target_size=target_size, detector_backend=detector_backend,\n","                                               grayscale=False, enforce_detection=enforce_detection, align=align)\n","        else:\n","            if isinstance(img_path, str):\n","                img = functions.load_image(img_path)\n","            elif type(img_path).__module__ == np.__name__:\n","                img = img_path.copy()\n","            else:\n","                raise ValueError(f\"unexpected type for img_path - {type(img_path)}\")\n","\n","            if len(img.shape) == 4:\n","                img = img[0]\n","            if len(img.shape) == 3:\n","                img = cv2.resize(img, target_size)\n","                img = np.expand_dims(img, axis=0)\n","\n","            img_region = [0, 0, img.shape[1], img.shape[0]]\n","            img_objs = [(img, img_region, 0)]\n","\n","        for img, region, _ in img_objs:\n","            img = functions.normalize_input(img=img, normalization=normalization)\n","\n","            if \"keras\" in str(type(model)):\n","                embedding = model.predict(img, verbose=0)[0].tolist()\n","            else:\n","                embedding = model.predict(img)[0].tolist()\n","\n","            resp_obj = {\"embedding\": embedding, \"facial_area\": region}\n","            resp_objs.append(resp_obj)\n","\n","        return resp_objs\n","\n","    def create_pkl_multiprocessing(self):\n","\n","        tik = time.time()\n","\n","        db_path = FACE_OUTPUT\n","        model_name = \"VGG-Face\"\n","        enforce_detection = False\n","        detector_backend = \"retinaface\"\n","        align = True\n","        normalization = \"base\"\n","        silent = False\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","\n","        pkl = f\"{db_path}/{file_name}\"\n","\n","        if os.path.exists(pkl):\n","            os.remove(pkl)\n","\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if ((\".jpg\" in file.lower()) or (\".jpeg\" in file.lower()) or (\".png\" in file.lower())):\n","                    exact_path = os.path.join(r, file)\n","                    employees.append(exact_path)\n","\n","        if len(employees) == 0:\n","            raise ValueError(\"There is no image in \", db_path, \" folder! Validate .jpg or .png files exist in this path.\")\n","\n","        representations = []\n","\n","        MAX_WORKERS = 6\n","\n","        with Pool(MAX_WORKERS) as pool:\n","            for batch_start in range(0, len(employees), MAX_WORKERS):\n","                batch_employees = employees[batch_start:batch_start + MAX_WORKERS]\n","                representations_list = list(tqdm(pool.imap(process_image, batch_employees), total=len(batch_employees), desc=\"Finding representations\", disable=silent))\n","                representations.extend([item for sublist in representations_list for item in sublist])\n","\n","        with open(pkl, \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(f\"Representations stored in {db_path}/{file_name}. Please delete this file when you add new identities in your database.\")\n","\n","        tok = time.time()\n","\n","        print(\"Multiprocessing: \",str(round(tok-tik)))\n","\n","    def create_pkl_nonopti(self):\n","\n","        tik = time.time()\n","\n","        db_path = FACE_OUTPUT\n","        model_name = \"VGG-Face\"\n","        enforce_detection = False\n","        detector_backend = \"retinaface\"\n","        align = True\n","        normalization = \"base\"\n","        silent = False\n","        target_size = functions.find_target_size(model_name=model_name)\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","\n","        pkl = f\"{db_path}/{file_name}\"\n","\n","\n","        if os.path.exists(pkl):\n","            os.remove(pkl)\n","\n","\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if (\n","                    (\".jpg\" in file.lower())\n","                    or (\".jpeg\" in file.lower())\n","                    or (\".png\" in file.lower())\n","                ):\n","                    exact_path = r + \"/\" + file\n","                    employees.append(exact_path)\n","\n","        if len(employees) == 0:\n","            raise ValueError(\n","                \"There is no image in \",\n","                db_path,\n","                \" folder! Validate .jpg or .png files exist in this path.\",\n","            )\n","\n","        # ------------------------\n","        # find representations for db images\n","\n","        representations = []\n","\n","        # for employee in employees:\n","        pbar = tqdm(\n","            range(0, len(employees)),\n","            desc=\"Finding representations\",\n","            disable=silent,\n","        )\n","        for index in pbar:\n","            employee = employees[index]\n","\n","            img_objs = functions.extract_faces(\n","                img=employee,\n","                target_size=target_size,\n","                detector_backend=detector_backend,\n","                grayscale=False,\n","                enforce_detection=enforce_detection,\n","                align=align,\n","            )\n","\n","            for img_content, _, _ in img_objs:\n","                embedding_obj = self.represent(\n","                    img_path=img_content,\n","                    model_name=model_name,\n","                    enforce_detection=enforce_detection,\n","                    detector_backend=\"skip\",\n","                    align=align,\n","                    normalization=normalization,\n","                )\n","\n","                img_representation = embedding_obj[0][\"embedding\"]\n","\n","                instance = []\n","                instance.append(employee)\n","                instance.append(img_representation)\n","                representations.append(instance)\n","\n","        # -------------------------------\n","\n","        with open(f\"{db_path}/{file_name}\", \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(\n","                f\"Representations stored in {db_path}/{file_name} file.\"\n","                + \"Please delete this file when you add new identities in your database.\"\n","            )\n","\n","        tok = time.time()\n","\n","        print(\"Non Optimized: \",str(round(tok-tik)))\n","\n","    def create_pkl_concurrent(self):\n","\n","        tik = time.time()\n","\n","        db_path = FACE_OUTPUT\n","        model_name = \"VGG-Face\"\n","        enforce_detection = False\n","        detector_backend = \"retinaface\"\n","        align = True\n","        normalization = \"base\"\n","        silent = False\n","        target_size = functions.find_target_size(model_name=model_name)\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","\n","        print(file_name)\n","\n","\n","        pkl = f\"{db_path}/{file_name}\"\n","\n","        if os.path.exists(pkl):\n","            os.remove(pkl)\n","\n","        print(pkl)\n","\n","        # Create a tqdm progress bar object\n","        progress_bar = tqdm(total=(len(os.listdir(os.path.join(DIRECTORY,FACE_OUTPUT)))), desc=\"Processing\", unit=\" items\")\n","\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if (\".jpg\" in file.lower()) or (\".jpeg\" in file.lower()) or (\".png\" in file.lower()):\n","                    exact_path = r + \"/\" + file\n","                    employees.append(exact_path)\n","\n","        if len(employees) == 0:\n","            raise ValueError( \"There is no image in \", db_path, \" folder! Validate .jpg or .png files exist in this path\")\n","\n","        representations = []\n","\n","        global count\n","        count = 0\n","\n","        def process_employee(employee):\n","            img_objs = functions.extract_faces( img=employee, target_size=target_size, detector_backend=detector_backend, grayscale=False, enforce_detection=enforce_detection, align=align, )\n","\n","            for img_content, _, _ in img_objs:\n","                embedding_obj = self.represent( img_path=img_content, model_name=model_name, enforce_detection=enforce_detection, detector_backend=\"skip\", align=align, normalization=normalization, )\n","\n","                img_representation = embedding_obj[0][\"embedding\"]\n","\n","                instance = []\n","                instance.append(employee)\n","                instance.append(img_representation)\n","                representations.append(instance)\n","                global count\n","                count += 1\n","                # print(count)\n","                progress_bar.update(1)\n","\n","\n","        # Create a ThreadPoolExecutor\n","        max_workers = PKL_MAX_WORKERS\n","        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n","            list(executor.map(process_employee, employees))\n","\n","        with open(f\"{db_path}/{file_name}\", \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(\n","                f\"Representations stored in {db_path}/{file_name} file.\"\n","                + \"Please delete this file when you add new identities in your database.\"\n","            )\n","\n","        # Close the progress bar\n","        progress_bar.close()\n","\n","        tok = time.time()\n","\n","        print(\"Concurrent Futures: \",str(round(tok-tik)))"]},{"cell_type":"markdown","metadata":{"id":"sYvYpizr7LKe"},"source":["# Main Play Area"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCFjY1Pv0Ky8"},"outputs":[],"source":["webcam = GoogleWebcam()\n","webcam.record_video(frames=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"E9oStjTjHEJH"},"outputs":[],"source":["face_extractor = FaceExtractor()\n","await face_extractor.video_to_faces_parallel()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fNHKGwDnHEh1"},"outputs":[],"source":["# cle = Cleanup()\n","# cle.clean()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"U85NcTfyHQTg"},"outputs":[],"source":["dp = Deep()\n","dp.create_pkl_concurrent()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPLC7XEAnmx9zkS6q1arHyl","collapsed_sections":["ByUo4uJQ6aVh","L6pCmkJrUC9g","MaZIOR4WaT64","AIYbi_aY7HIk"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
