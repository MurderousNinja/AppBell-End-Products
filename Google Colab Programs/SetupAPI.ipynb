{"cells":[{"cell_type":"markdown","metadata":{"id":"HkIIHAqNrDMc"},"source":["# All"]},{"cell_type":"markdown","metadata":{"id":"L4aJ8CF9J_th"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1696933998335,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"tK_8UjadJ8dL"},"outputs":[],"source":["# Standard Library Imports\n","import os\n","import pickle\n","import shutil\n","import time\n","from concurrent.futures import ThreadPoolExecutor\n","import os\n","import cv2\n","import asyncio\n","import numpy as np\n","from base64 import b64decode\n","from IPython.display import Javascript, display\n","import asyncio\n","import threading"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39899,"status":"ok","timestamp":1696934057728,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"5lg1c83cltAC","outputId":"b7c0cb37-8d04-4d53-9177-2ef68f32805a"},"outputs":[],"source":["!pip install fastapi\n","!pip install deepface\n","!pip install uvicorn\n","!pip install retinaface\n","!pip install colabcode\n","!pip install pyngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5683,"status":"ok","timestamp":1696934063402,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"bCmfb7onKxOo","outputId":"10dea359-aa0f-499f-b277-c34bf6588602"},"outputs":[],"source":["# Third-party Library Imports\n","import numpy as np\n","import cv2\n","from os import path\n","from tqdm import tqdm\n","from fastapi import FastAPI\n","from fastapi.responses import HTMLResponse, RedirectResponse\n","from retinaface import RetinaFace\n","from deepface import DeepFace\n","import deepface.commons.functions as functions\n","from colabcode import ColabCode\n","import cv2\n","import numpy as np\n","import io\n","import PIL\n","from base64 import b64decode, b64encode\n","from pyngrok import ngrok\n","from multiprocessing import Pool"]},{"cell_type":"markdown","metadata":{"id":"IElr6quC1NHY"},"source":["## Setting Up Weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16912,"status":"ok","timestamp":1696934080307,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"SB-C2BYqd8hB","outputId":"dd0dfa01-97ad-46c8-8a7a-b5f27b3c7e01"},"outputs":[],"source":["DeepFace.build_model(\"VGG-Face\")"]},{"cell_type":"markdown","metadata":{"id":"0VlX2o9BLQCD"},"source":["## Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1696934080308,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"IJlR8mmQLSmv"},"outputs":[],"source":["FACE_MAX_WORKERS = 14\n","PKL_MAX_WORKERS = 12\n","DIRECTORY = os.getcwd()\n","RECORDED_FOLDER = \"Recorded\"\n","FACE_FOLDER = \"Data\"\n","PROCESSING_FOLDER = \"Processing\"\n","FACE_THRESHOLD = 0.99\n","FPS = 30\n","CAMERA_INDEX = 0\n","MODEL_NAME = \"VGG-Face\"\n","PKL_FOLDER = \"PKL\""]},{"cell_type":"markdown","metadata":{"id":"T7AY2I_ILbWs"},"source":["## Database Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1696934080308,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"AHyIaBjzLe5L"},"outputs":[],"source":["folders = [FACE_FOLDER, RECORDED_FOLDER, PROCESSING_FOLDER, PKL_FOLDER]\n","\n","# Create output directories if they don't exist\n","for folder in folders:\n","    if not os.path.exists(folder):\n","        os.makedirs(folder)"]},{"cell_type":"markdown","metadata":{"id":"1EBJO2LbLj_Z"},"source":["## API Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1696934080308,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"Vn2LAdKRLfRX"},"outputs":[],"source":["app = FastAPI()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1696934081271,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"UbcdknNVe-DG"},"outputs":[],"source":["cc = ColabCode(port=12000, code=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2953,"status":"ok","timestamp":1696934084215,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"tBjQMQCfl4Jc","outputId":"256732c2-3d7a-4b05-e846-fbd2f8862719"},"outputs":[],"source":["# Provide your Ngrok auth token\n","auth_token = \"2VQ3N6dnV7bMo5PhJskNw6KOynM_43X2AJPHbCN42wdjt29jb\"\n","\n","# Set the auth token for Ngrok\n","ngrok.set_auth_token(auth_token)"]},{"cell_type":"markdown","metadata":{"id":"OVp5Qg0-qEvp"},"source":["## Useful Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1696934084216,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"Qh16MP_UT6jZ"},"outputs":[],"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","async def take_photo_async(filename='photo.jpg', quality=0.8):\n","    js = Javascript('''\n","      async function takePhoto(quality) {\n","        const div = document.createElement('div');\n","\n","        const video = document.createElement('video');\n","        video.style.display = 'block';\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","        document.body.appendChild(div);\n","        div.appendChild(video);\n","        video.srcObject = stream;\n","        await video.play();\n","\n","        // Resize the output to fit the video element.\n","        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","        const canvas = document.createElement('canvas');\n","        canvas.width = video.videoWidth;\n","        canvas.height = video.videoHeight;\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        stream.getVideoTracks()[0].stop();\n","        div.remove();\n","        return canvas.toDataURL('image/jpeg', quality);\n","        }\n","    ''')\n","\n","    display(js)\n","    data = eval_js('takePhoto({})'.format(quality))\n","    binary = b64decode(data.split(',')[1])\n","\n","    print(filename)\n","\n","    with open(filename, 'wb') as f:\n","        f.write(binary)\n","\n","    return filename"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1696934084217,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"2CrAc9kGdOeV"},"outputs":[],"source":["async def capture_photos(number=100):\n","    tasks = []\n","\n","    for i in range(number):\n","        filename = f\"{RECORDED_FOLDER}/Frame {i}.jpg\"\n","        task = asyncio.create_task(take_photo_async(filename=filename))\n","        tasks.append(task)\n","\n","    await asyncio.gather(*tasks)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1696934084217,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"g5X-omKFT6ja"},"outputs":[],"source":["from IPython.display import Image\n","import os\n","\n","def take_pics(number=100):\n","    try:\n","        if not os.path.exists(RECORDED_FOLDER):\n","            os.makedirs(RECORDED_FOLDER)\n","\n","        loop = asyncio.get_event_loop()\n","        loop.run_until_complete(capture_photos(number))\n","\n","        print(\"Photos captured successfully!\")\n","    except Exception as err:\n","        # Handle errors\n","        print(str(err))\n"]},{"cell_type":"markdown","metadata":{"id":"ZIhz-0AOL8Sl"},"source":["## Functionality Classes"]},{"cell_type":"markdown","metadata":{"id":"DtPLqlfjLwiM"},"source":["### Face Extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1696934084218,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"eyZvwvYfL7A5"},"outputs":[],"source":["# Define a class for face extraction\n","class FaceExtractor:\n","    def process_frame(self, frame, id):\n","        try:\n","            count = os.path.split(frame)[1].split(' ')[1].split('.')[0]\n","\n","            # Use RetinaFace to extract faces from the frame\n","            faces = RetinaFace.extract_faces(frame, threshold = FACE_THRESHOLD, model = None, allow_upscaling = True)\n","\n","            if not faces:\n","                print(f\"No faces extracted in Frame {count}.\")\n","                return None\n","\n","            path0 = os.path.join(DIRECTORY, PROCESSING_FOLDER)\n","            if not os.path.exists(path0):\n","                os.makedirs(path0)\n","\n","            image_sizes = [np.prod(image.shape) for image in faces]\n","            largest_index = np.argmax(image_sizes)\n","            filename2 = f\"user.{id}.{count}.jpg\"\n","            result = os.path.join(path0, filename2)\n","            print(f\"user.{id}.{count}.jpg written\")\n","            cv2.imwrite(result, faces[largest_index])\n","\n","            return count\n","\n","        except Exception as e:\n","            print(str(e))\n","            return None\n","\n","    def video_to_faces_parallel(self, frames, id):\n","        with ThreadPoolExecutor(max_workers = FACE_MAX_WORKERS) as executor:  # Adjust max_workers as needed\n","            futures = [executor.submit(self.process_frame, frame, id) for frame in frames]\n","            for future in futures:\n","                future.result()  # Wait for the threads to complete"]},{"cell_type":"markdown","metadata":{"id":"2iyxj9cTLyXJ"},"source":["### Class Cleanup"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1696934084218,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"rEPkE72BMHsp"},"outputs":[],"source":["class Cleanup:\n","    @staticmethod\n","    def clean():\n","        directory_path1 = os.path.join(DIRECTORY, RECORDED_FOLDER)\n","        directory_path2 = os.path.join(DIRECTORY, PROCESSING_FOLDER)\n","        try:\n","            shutil.rmtree(directory_path1)\n","            print(f'Directory \"{directory_path1}\" and its contents have been successfully deleted.')\n","            shutil.rmtree(directory_path2)\n","            print(f'Directory \"{directory_path2}\" and its contents have been successfully deleted.')\n","        except Exception as e:\n","            print(f'An error occurred: {e}')\n","\n","    @staticmethod\n","    def move():\n","        old_fold = os.path.join(DIRECTORY, PROCESSING_FOLDER)\n","        new_fold = os.path.join(DIRECTORY, FACE_FOLDER)\n","\n","        if not os.path.exists(FACE_FOLDER):\n","            os.makedirs(FACE_FOLDER)\n","\n","        for filename in os.listdir(old_fold):\n","            old_name = os.path.join(old_fold, filename)\n","            new_name = os.path.join(new_fold, filename)\n","            if not os.path.exists(new_name):\n","                os.rename(old_name, new_name)\n","            else:\n","                os.remove(new_name)\n","                os.rename(old_name,new_name)\n","\n","        print(\"Moved!!\")"]},{"cell_type":"markdown","metadata":{"id":"u_iGcvIZLuks"},"source":["### Class Deep"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1696934084218,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"PrwkG7hOLuGh"},"outputs":[],"source":["class Deep:\n","    @staticmethod\n","    def represent(img_path, model_name = \"VGG-Face\", enforce_detection = True, detector_backend = \"retinaface\", align = True, normalization = \"base\"):\n","        resp_objs = []\n","\n","        model = DeepFace.build_model(model_name)\n","\n","        # ---------------------------------\n","        # we have run pre-process in verification. so, this can be skipped if it is coming from verify.\n","        target_size = functions.find_target_size(model_name = model_name)\n","        if detector_backend  != \"skip\":\n","            img_objs = functions.extract_faces( img = img_path, target_size = target_size, detector_backend = detector_backend, grayscale = False, enforce_detection = enforce_detection, align = align, )\n","        else:  # skip\n","            if isinstance(img_path, str):\n","                img = functions.load_image(img_path)\n","            elif type(img_path).__module__  == np.__name__:\n","                img = img_path.copy()\n","            else:\n","                raise ValueError(f\"unexpected type for img_path - {type(img_path)}\")\n","            # --------------------------------\n","            if len(img.shape)  == 4:\n","                img = img[0]  # e.g. (1, 224, 224, 3) to (224, 224, 3)\n","            if len(img.shape)  == 3:\n","                img = cv2.resize(img, target_size)\n","                img = np.expand_dims(img, axis = 0)\n","            # --------------------------------\n","            img_region = [0, 0, img.shape[1], img.shape[0]]\n","            img_objs = [(img, img_region, 0)]\n","        # ---------------------------------\n","\n","        for img, region, _ in img_objs:\n","            # custom normalization\n","            img = functions.normalize_input(img = img, normalization = normalization)\n","\n","            # represent\n","            if \"keras\" in str(type(model)):\n","                # new tf versions show progress bar and it is annoying\n","                embedding = model.predict(img, verbose = 0)[0].tolist()\n","            else:\n","                # SFace and Dlib are not keras models and no verbose arguments\n","                embedding = model.predict(img)[0].tolist()\n","\n","            resp_obj = {}\n","            resp_obj[\"embedding\"] = embedding\n","            resp_obj[\"facial_area\"] = region\n","            resp_objs.append(resp_obj)\n","\n","        return resp_objs\n","\n","    def Create_PKL(self, model_name = \"VGG-Face\", distance_metric = \"cosine\", enforce_detection = False, detector_backend = \"opencv\", align = True, normalization = \"base\", silent = False, bid = 0000):\n","        tic = time.time()\n","\n","        db_path = PROCESSING_FOLDER\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","        pkl = f\"{PKL_FOLDER}/{bid}_{file_name}\"\n","\n","        # -------------------------------\n","        if os.path.isdir(db_path) is not True:\n","            raise ValueError(\"Passed db_path does not exist!\")\n","\n","        target_size = functions.find_target_size(model_name = model_name)\n","\n","        # create representation.pkl from scratch\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if ((\".jpg\" in file.lower()) or (\".jpeg\" in file.lower()) or (\".png\" in file.lower())):\n","                    exact_path = r + \"/\" + file\n","                    employees.append(exact_path)\n","\n","        if len(employees)  == 0:\n","            raise ValueError(\"There is no image in \", db_path, \" folder! Validate .jpg or .png files exist in this path.\")\n","\n","        # ------------------------\n","        # find representations for db images\n","\n","        representations = []\n","\n","        # for employee in employees:\n","        pbar = tqdm(range(0, len(employees)), desc = \"Finding representations\", disable = silent)\n","        for index in pbar:\n","            employee = employees[index]\n","\n","            img_objs = functions.extract_faces(img = employee, target_size = target_size, detector_backend = detector_backend, grayscale = False, enforce_detection = enforce_detection, align = align)\n","\n","            for img_content, _, _ in img_objs:\n","                embedding_obj = self.represent(img_path = img_content, model_name = model_name, enforce_detection = enforce_detection, detector_backend = \"skip\", align = align, normalization = normalization)\n","\n","                img_representation = embedding_obj[0][\"embedding\"]\n","\n","                instance = []\n","                instance.append(employee)\n","                instance.append(img_representation)\n","                representations.append(instance)\n","\n","        print(pkl)\n","\n","        if path.exists(pkl):\n","            with open(pkl, \"rb\") as f:\n","                representations_present = pickle.load(f)\n","\n","                representations.extend(representations_present)\n","\n","            backup_pkl = pkl.split('.')[0] + \"_Backup.pkl\"\n","\n","            os.rename(pkl, backup_pkl)\n","\n","        with open(pkl, \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(\n","                f\"Representations stored in {pkl} file.\"\n","                + \"Please delete this file when you add new identities in your database.\"\n","            )"]},{"cell_type":"markdown","metadata":{"id":"T0QpDhRjMafV"},"source":["## API Functions"]},{"cell_type":"markdown","metadata":{"id":"4Cr81TQVNBFP"},"source":["### Home Page"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1696934084219,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"CPw3p1iUNAfD"},"outputs":[],"source":["@app.get(\"/\", response_class=HTMLResponse)\n","async def home():\n","    html_content = \"\"\"\n","    <!DOCTYPE html>\n","    <html>\n","    <head>\n","        <title>Prerecording</title>\n","    </head>\n","    <body>\n","        <div class=\"center-text\">\n","            <h1>Welcome to the FastAPI API</h1>\n","        </div>\n","\n","        <form method=\"GET\" action=\"/processing_video\">\n","            <label for=\"id\">Enter an ID:</label>\n","            <input type=\"text\" id=\"id\" name=\"id\" required>\n","\n","            <label for=\"bid\">Enter your Buisness ID:</label>\n","            <input type=\"text\" id=\"bid\" name=\"bid\" required>\n","\n","            <button type=\"submit\">Let's start recording and processing!</button>\n","        </form>\n","    </body>\n","    </html>\n","    \"\"\"\n","    return HTMLResponse(content=html_content)"]},{"cell_type":"markdown","metadata":{"id":"cYgA4NvcNItl"},"source":["### Recording Page"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1696934084219,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"62d8VGLmNH3x"},"outputs":[],"source":["@app.get(\"/processing_video\", response_class = RedirectResponse)\n","async def processing_video(id: str, bid: str):\n","    try:\n","        # Initialize the Class Object\n","        face_extractor = FaceExtractor()\n","        deep_processor = Deep()\n","\n","        take_pics(number = 10)\n","\n","        frames = list(os.path.join(RECORDED_FOLDER, a) for a in os.listdir(RECORDED_FOLDER))\n","\n","        print(frames)\n","\n","        # Process frames in parallel to extract faces\n","        face_extractor.video_to_faces_parallel(frames, id)\n","\n","        deep_processor.Create_PKL(bid = bid)\n","\n","        # Move processed frames to the data folder\n","        Cleanup.move()\n","\n","        Cleanup.clean()\n","\n","        return RedirectResponse(\"/postfacerep\", status_code = 200)\n","\n","    except Exception as e:\n","\n","        return {\"error\": str(e)}"]},{"cell_type":"markdown","metadata":{"id":"uPYaB6YSNPMC"},"source":["### Done Page"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1696934084220,"user":{"displayName":"Chinmay Patil","userId":"17467446507430458214"},"user_tz":-330},"id":"f2Rx8Ir6XQFL"},"outputs":[],"source":["@app.get(\"/postfacerep\", response_class = HTMLResponse)\n","async def postrep():\n","    html_content = \"\"\"\n","    <!DOCTYPE html>\n","    <html>\n","    <head>\n","        <title>Face Extraction Done!</title>\n","    </head>\n","    <body>\n","        <div class = \"center-text\">\n","            <h1>Face Representation Done</h1>\n","        </div>\n","    </body>\n","    </html>\n","    \"\"\"\n","\n","    # Clean up recorded and processed frames\n","\n","    return HTMLResponse(content = html_content)"]},{"cell_type":"markdown","metadata":{"id":"UekEavD4XUaP"},"source":["# Calling Program Page"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BVP2E1oIXYIu"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    cc.run_app(app=app)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNQgvZM3hgSspCSdKXlsl+j","collapsed_sections":["L4aJ8CF9J_th","IElr6quC1NHY","0VlX2o9BLQCD","T7AY2I_ILbWs","1EBJO2LbLj_Z","OVp5Qg0-qEvp","2iyxj9cTLyXJ","u_iGcvIZLuks","4Cr81TQVNBFP","uPYaB6YSNPMC"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
