{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["0VlX2o9BLQCD","T7AY2I_ILbWs","1EBJO2LbLj_Z","ZIhz-0AOL8Sl","m-Ppwxy2LnPE","DtPLqlfjLwiM","2iyxj9cTLyXJ","u_iGcvIZLuks","T0QpDhRjMafV","4Cr81TQVNBFP","cYgA4NvcNItl","uPYaB6YSNPMC"],"authorship_tag":"ABX9TyOH9FRrYA07kq+7hSTPfkDw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"L4aJ8CF9J_th"}},{"cell_type":"code","execution_count":34,"metadata":{"id":"tK_8UjadJ8dL","executionInfo":{"status":"ok","timestamp":1696503528849,"user_tz":-330,"elapsed":516,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"outputs":[],"source":["# Standard Library Imports\n","import os\n","import pickle\n","import shutil\n","import time\n","from concurrent.futures import ThreadPoolExecutor"]},{"cell_type":"code","source":["!pip install fastapi"],"metadata":{"id":"iWPPY2fLK1cJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install deepface"],"metadata":{"id":"i2R_C2xnLE4n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install uvicorn"],"metadata":{"id":"ZV631bToLF7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install retinaface"],"metadata":{"id":"0_RG5-MTLKeb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install colabcode"],"metadata":{"id":"8DRWN5Dmew6N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Third-party Library Imports\n","import numpy as np\n","import cv2\n","from os import path\n","from tqdm import tqdm\n","from fastapi import FastAPI\n","from fastapi.responses import HTMLResponse, RedirectResponse\n","from retinaface import RetinaFace\n","from deepface import DeepFace\n","import deepface.commons.functions as functions\n","from colabcode import ColabCode"],"metadata":{"id":"bCmfb7onKxOo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Constants"],"metadata":{"id":"0VlX2o9BLQCD"}},{"cell_type":"code","source":["FACE_MAX_WORKERS = 14\n","PKL_MAX_WORKERS = 12\n","DIRECTORY = os.getcwd()\n","RECORDED_FOLDER = \"Recorded\"\n","FACE_FOLDER = \"Data\"\n","PROCESSING_FOLDER = \"Processing\"\n","FACE_THRESHOLD = 0.99\n","FPS = 30\n","CAMERA_INDEX = 0\n","MODEL_NAME = \"VGG-Face\"\n","PKL_FOLDER = \"PKL\""],"metadata":{"id":"IJlR8mmQLSmv","executionInfo":{"status":"ok","timestamp":1696501672787,"user_tz":-330,"elapsed":485,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# Database Setup"],"metadata":{"id":"T7AY2I_ILbWs"}},{"cell_type":"code","source":["folders = [FACE_FOLDER, RECORDED_FOLDER, PROCESSING_FOLDER, PKL_FOLDER]\n","\n","# Create output directories if they don't exist\n","for folder in folders:\n","    if not os.path.exists(folder):\n","        os.makedirs(folder)"],"metadata":{"id":"AHyIaBjzLe5L","executionInfo":{"status":"ok","timestamp":1696501674313,"user_tz":-330,"elapsed":2,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# API Setup"],"metadata":{"id":"1EBJO2LbLj_Z"}},{"cell_type":"code","source":["app = FastAPI()"],"metadata":{"id":"Vn2LAdKRLfRX","executionInfo":{"status":"ok","timestamp":1696501675909,"user_tz":-330,"elapsed":2,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["cc = ColabCode(port=12000, code=False)"],"metadata":{"id":"UbcdknNVe-DG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functionality Classes"],"metadata":{"id":"ZIhz-0AOL8Sl"}},{"cell_type":"markdown","source":["## Class Webcam Recorder"],"metadata":{"id":"m-Ppwxy2LnPE"}},{"cell_type":"code","source":["class WebcamRecorder:\n","\n","    def __init__(self, camera_index = 0):\n","        self.camera_index = camera_index\n","        self.capture = cv2.VideoCapture(self.camera_index)\n","        if not self.capture.isOpened():\n","            raise Exception(\"Could not open the webcam.\")\n","\n","    def get_frame(self):\n","        ret, frame = self.capture.read()\n","        if not ret:\n","            raise Exception(\"Could not read a frame from the webcam.\")\n","        return frame\n","\n","    def generate_filename(self, count):\n","        return f'Frame {count:02d}.jpg'\n","\n","    def record_video(self):\n","        count = -1\n","        frames = []\n","        while True:\n","            count +=  1\n","            filename = os.path.join(RECORDED_FOLDER, self.generate_filename(count))\n","            frame = self.get_frame()\n","            frames.append(frame)\n","            cv2.imwrite(filename, frame)\n","            print(filename)\n","            cv2.imshow('Webcam Feed', frame)\n","            if cv2.waitKey(1000 // FPS) & 0xFF  == ord('q') or count > 98:\n","                break\n","\n","        self.capture.release()\n","        cv2.destroyAllWindows()\n","\n","        return frames"],"metadata":{"id":"oFc_1y_OLrku","executionInfo":{"status":"ok","timestamp":1696501678867,"user_tz":-330,"elapsed":430,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Face Extraction"],"metadata":{"id":"DtPLqlfjLwiM"}},{"cell_type":"code","source":["class FaceExtractor:\n","    def process_frame(self, frame, id):\n","        try:\n","            count = frame.split('\\\\')[1].split(' ')[1].split('.')[0]\n","\n","            # Use RetinaFace to extract faces from the frame\n","            faces = RetinaFace.extract_faces(frame, threshold = FACE_THRESHOLD, model = None, allow_upscaling = True)\n","\n","            if not faces:\n","                print(f\"No faces extracted in Frame {count}.\")\n","                return None\n","\n","            path0 = os.path.join(DIRECTORY, PROCESSING_FOLDER)\n","            if not os.path.exists(path0):\n","                os.makedirs(path0)\n","\n","            image_sizes = [np.prod(image.shape) for image in faces]\n","            largest_index = np.argmax(image_sizes)\n","            filename2 = f\"user.{id}.{count}.jpg\"\n","            result = os.path.join(path0, filename2)\n","            print(f\"user.{id}.{count}.jpg written\")\n","            cv2.imwrite(result, faces[largest_index])\n","\n","            return count\n","\n","        except Exception as e:\n","            print(str(e))\n","            return None\n","\n","    def video_to_faces_parallel(self, frames, id):\n","        with ThreadPoolExecutor(max_workers = FACE_MAX_WORKERS) as executor:  # Adjust max_workers as needed\n","            futures = [executor.submit(self.process_frame, frame, id) for frame in frames]\n","            for future in futures:\n","                future.result()  # Wait for the threads to complete"],"metadata":{"id":"eyZvwvYfL7A5","executionInfo":{"status":"ok","timestamp":1696501679664,"user_tz":-330,"elapsed":3,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Class Cleanup"],"metadata":{"id":"2iyxj9cTLyXJ"}},{"cell_type":"code","source":["class Cleanup:\n","    @staticmethod\n","    def clean():\n","        directory_path1 = os.path.join(DIRECTORY, RECORDED_FOLDER)\n","        directory_path2 = os.path.join(DIRECTORY, PROCESSING_FOLDER)\n","        try:\n","            shutil.rmtree(directory_path1)\n","            print(f'Directory \"{directory_path1}\" and its contents have been successfully deleted.')\n","            shutil.rmtree(directory_path2)\n","            print(f'Directory \"{directory_path2}\" and its contents have been successfully deleted.')\n","        except Exception as e:\n","            print(f'An error occurred: {e}')\n","\n","    @staticmethod\n","    def move():\n","        old_fold = os.path.join(DIRECTORY, PROCESSING_FOLDER)\n","        new_fold = os.path.join(DIRECTORY, FACE_FOLDER)\n","\n","        if not os.path.exists(FACE_FOLDER):\n","            os.makedirs(FACE_FOLDER)\n","\n","        for filename in os.listdir(old_fold):\n","            old_name = os.path.join(old_fold, filename)\n","            new_name = os.path.join(new_fold, filename)\n","            if not os.path.exists(new_name):\n","                os.rename(old_name, new_name)\n","            else:\n","                os.remove(new_name)\n","                os.rename(old_name,new_name)\n","\n","        print(\"Moved!!\")"],"metadata":{"id":"rEPkE72BMHsp","executionInfo":{"status":"ok","timestamp":1696501679664,"user_tz":-330,"elapsed":2,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## Class Deep"],"metadata":{"id":"u_iGcvIZLuks"}},{"cell_type":"code","source":["class Deep:\n","    @staticmethod\n","    def represent(img_path, model_name = \"VGG-Face\", enforce_detection = True, detector_backend = \"retinaface\", align = True, normalization = \"base\"):\n","        resp_objs = []\n","\n","        model = DeepFace.build_model(model_name)\n","\n","        # ---------------------------------\n","        # we have run pre-process in verification. so, this can be skipped if it is coming from verify.\n","        target_size = functions.find_target_size(model_name = model_name)\n","        if detector_backend  != \"skip\":\n","            img_objs = functions.extract_faces( img = img_path, target_size = target_size, detector_backend = detector_backend, grayscale = False, enforce_detection = enforce_detection, align = align, )\n","        else:  # skip\n","            if isinstance(img_path, str):\n","                img = functions.load_image(img_path)\n","            elif type(img_path).__module__  == np.__name__:\n","                img = img_path.copy()\n","            else:\n","                raise ValueError(f\"unexpected type for img_path - {type(img_path)}\")\n","            # --------------------------------\n","            if len(img.shape)  == 4:\n","                img = img[0]  # e.g. (1, 224, 224, 3) to (224, 224, 3)\n","            if len(img.shape)  == 3:\n","                img = cv2.resize(img, target_size)\n","                img = np.expand_dims(img, axis = 0)\n","            # --------------------------------\n","            img_region = [0, 0, img.shape[1], img.shape[0]]\n","            img_objs = [(img, img_region, 0)]\n","        # ---------------------------------\n","\n","        for img, region, _ in img_objs:\n","            # custom normalization\n","            img = functions.normalize_input(img = img, normalization = normalization)\n","\n","            # represent\n","            if \"keras\" in str(type(model)):\n","                # new tf versions show progress bar and it is annoying\n","                embedding = model.predict(img, verbose = 0)[0].tolist()\n","            else:\n","                # SFace and Dlib are not keras models and no verbose arguments\n","                embedding = model.predict(img)[0].tolist()\n","\n","            resp_obj = {}\n","            resp_obj[\"embedding\"] = embedding\n","            resp_obj[\"facial_area\"] = region\n","            resp_objs.append(resp_obj)\n","\n","        return resp_objs\n","\n","\n","    def Create_PKL(self, model_name = \"VGG-Face\", distance_metric = \"cosine\", enforce_detection = False, detector_backend = \"opencv\", align = True, normalization = \"base\", silent = False):\n","        tic = time.time()\n","\n","        db_path = PROCESSING_FOLDER\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","        pkl = f\"{PKL_FOLDER}/{file_name}\"\n","\n","        # -------------------------------\n","        if os.path.isdir(db_path) is not True:\n","            raise ValueError(\"Passed db_path does not exist!\")\n","\n","        target_size = functions.find_target_size(model_name = model_name)\n","\n","        # create representation.pkl from scratch\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if ((\".jpg\" in file.lower()) or (\".jpeg\" in file.lower()) or (\".png\" in file.lower())):\n","                    exact_path = r + \"/\" + file\n","                    employees.append(exact_path)\n","\n","        if len(employees)  == 0:\n","            raise ValueError(\"There is no image in \", db_path, \" folder! Validate .jpg or .png files exist in this path.\")\n","\n","        # ------------------------\n","        # find representations for db images\n","\n","        representations = []\n","\n","        # for employee in employees:\n","        pbar = tqdm(range(0, len(employees)), desc = \"Finding representations\", disable = silent)\n","        for index in pbar:\n","            employee = employees[index]\n","\n","            img_objs = functions.extract_faces(img = employee, target_size = target_size, detector_backend = detector_backend, grayscale = False, enforce_detection = enforce_detection, align = align)\n","\n","            for img_content, _, _ in img_objs:\n","                embedding_obj = self.represent(img_path = img_content, model_name = model_name, enforce_detection = enforce_detection, detector_backend = \"skip\", align = align, normalization = normalization)\n","\n","                img_representation = embedding_obj[0][\"embedding\"]\n","\n","                instance = []\n","                instance.append(employee)\n","                instance.append(img_representation)\n","                representations.append(instance)\n","\n","        # -------------------------------\n","\n","        print(pkl)\n","\n","        if path.exists(pkl):\n","            with open(pkl, \"rb\") as f:\n","                representations_present = pickle.load(f)\n","\n","                representations.extend(representations_present)\n","\n","            with open(pkl, \"ab\") as f:\n","                pickle.dump(representations, f)\n","\n","        with open(pkl, \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(\n","                f\"Representations stored in {pkl} file.\"\n","                + \"Please delete this file when you add new identities in your database.\"\n","            )"],"metadata":{"id":"PrwkG7hOLuGh","executionInfo":{"status":"ok","timestamp":1696501679664,"user_tz":-330,"elapsed":2,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["# API Functions"],"metadata":{"id":"T0QpDhRjMafV"}},{"cell_type":"markdown","source":["## Home Page"],"metadata":{"id":"4Cr81TQVNBFP"}},{"cell_type":"code","source":["@app.get(\"/\", response_class = HTMLResponse)\n","async def home():\n","    html_content = \"\"\"\n","    <!DOCTYPE html>\n","    <html>\n","    <head>\n","        <title>Prerecording</title>\n","    </head>\n","    <body>\n","        <div class = \"center-text\">\n","            <h1>Welcome to the FastAPI API</h1>\n","        </div>\n","\n","        <form method = \"GET\" action = \"/processing_video\">\n","            <label for = \"id\">Enter an ID:</label>\n","            <input type = \"text\" id = \"id\" name = \"id\" required>\n","            <button type = \"submit\">Let's start recording and processing!</button>\n","        </form>\n","    </body>\n","    </html>\n","    \"\"\"\n","    return HTMLResponse(content = html_content)"],"metadata":{"id":"CPw3p1iUNAfD","executionInfo":{"status":"ok","timestamp":1696501681333,"user_tz":-330,"elapsed":3,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["## Recording Page"],"metadata":{"id":"cYgA4NvcNItl"}},{"cell_type":"code","source":["@app.get(\"/processing_video\", response_class = RedirectResponse)\n","async def processing_video(id: str):\n","    try:\n","        # Initialize the Class Object\n","        recorder = WebcamRecorder(camera_index = CAMERA_INDEX)\n","        face_extractor = FaceExtractor()\n","        deep_processor = Deep()\n","\n","        # Record the video and get frames\n","        recorder.record_video()\n","\n","        frames = list(os.path.join(RECORDED_FOLDER, a) for a in os.listdir(RECORDED_FOLDER))\n","\n","        # Process frames in parallel to extract faces\n","        face_extractor.video_to_faces_parallel(frames, id)\n","\n","        deep_processor.Create_PKL()\n","\n","        # Move processed frames to the data folder\n","        Cleanup.move()\n","\n","        print(\"Almost There!!!!\")\n","\n","        Cleanup.clean()\n","\n","        return RedirectResponse(\"/postfacerep\", status_code = 200)\n","\n","    except Exception as e:\n","\n","        return {\"error\": str(e)}"],"metadata":{"id":"62d8VGLmNH3x","executionInfo":{"status":"ok","timestamp":1696501681334,"user_tz":-330,"elapsed":3,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["## Done Page"],"metadata":{"id":"uPYaB6YSNPMC"}},{"cell_type":"code","source":["@app.get(\"/postfacerep\", response_class = HTMLResponse)\n","async def postrep():\n","    html_content = \"\"\"\n","    <!DOCTYPE html>\n","    <html>\n","    <head>\n","        <title>Face Extraction Done!</title>\n","    </head>\n","    <body>\n","        <div class = \"center-text\">\n","            <h1>Face Representation Done</h1>\n","        </div>\n","    </body>\n","    </html>\n","    \"\"\"\n","\n","    # Clean up recorded and processed frames\n","\n","    return HTMLResponse(content = html_content)"],"metadata":{"id":"f2Rx8Ir6XQFL","executionInfo":{"status":"ok","timestamp":1696501681334,"user_tz":-330,"elapsed":3,"user":{"displayName":"Chinmay Patil","userId":"08628623530181670034"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["# Calling Program Page"],"metadata":{"id":"UekEavD4XUaP"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    cc.run_app(app=app)\n"],"metadata":{"id":"BVP2E1oIXYIu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EXUfYMXcfiEu"},"execution_count":null,"outputs":[]}]}