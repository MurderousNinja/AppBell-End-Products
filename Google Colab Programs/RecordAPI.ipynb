{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMralR+FCb4azvY0t6Dlc6L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6iNyTD8WByc8"},"outputs":[],"source":["# Standard Library Imports\n","import os\n","import pickle\n","import shutil\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SX3Uj9ZECRDA"},"outputs":[],"source":["!pip install fastapi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csqsJEoyCOfj"},"outputs":[],"source":["# Third-party Library Imports\n","import concurrent.futures\n","from concurrent.futures import ThreadPoolExecutor\n","import cv2\n","import numpy as np\n","from fastapi import FastAPI, HTTPException\n","from fastapi.responses import HTMLResponse, RedirectResponse\n","from multiprocessing import Pool\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YsU3okzJCfAK"},"outputs":[],"source":["pip install deepface"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r2ZfCZC0CfF8"},"outputs":[],"source":["# Deep Learning Model Imports\n","from deepface import DeepFace as dpf\n","from deepface.commons import functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4cIwCMqWClPb"},"outputs":[],"source":["pip install retinaface"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jABxAF7CkZc"},"outputs":[],"source":["# Computer Vision Model Imports\n","from retinaface import RetinaFace"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yc1RGSkmDvr-"},"outputs":[],"source":["pip install uvicorn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8_7KhOQvDyGb"},"outputs":[],"source":["import uvicorn"]},{"cell_type":"code","source":["# Visualization\n","import matplotlib.pyplot as plt"],"metadata":{"id":"6PX5zFDJyxAd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXfOpOS_Cu4P"},"outputs":[],"source":["# Creating the fastapi object\n","app = FastAPI()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_7U87HHGC5RY"},"outputs":[],"source":["# Constants\n","FACE_MAX_WORKERS = 14\n","PKL_MAX_WORKERS = 12\n","RECORDING_OUTPUT = \"Frames\"\n","FACE_OUTPUT = \"Data\"\n","FACE_THRESHOLD = 0.99\n","FPS = 30\n","CAMERA_INDEX = 0\n","DIRECTORY = os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoLlwMMmC6i9"},"outputs":[],"source":["def process_image(employee):\n","    model_name = \"VGG-Face\"\n","    enforce_detection = False\n","    detector_backend = \"retinaface\"\n","    align = True\n","    normalization = \"base\"\n","\n","    target_size = functions.find_target_size(model_name=model_name)\n","\n","    img_objs = functions.extract_faces(img=employee, target_size=target_size, detector_backend=detector_backend, grayscale=False, enforce_detection=enforce_detection, align=align)\n","    representations = []\n","    for img_content, _, _ in img_objs:\n","        embedding_obj = Deep.represent(img_path=img_content, model_name=model_name, enforce_detection=enforce_detection, detector_backend=\"skip\", align=align, normalization=normalization)\n","        img_representation = embedding_obj[0][\"embedding\"]\n","        instance = [employee, img_representation]\n","        representations.append(instance)\n","    return representations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bd5n4E4DC-Om"},"outputs":[],"source":["class WebcamRecorder:\n","    def __init__(self, camera_index=CAMERA_INDEX):\n","        self.camera_index = camera_index\n","        self.capture = cv2.VideoCapture(self.camera_index)\n","        if not self.capture.isOpened():\n","            raise Exception(\"Could not open the webcam.\")\n","\n","    def get_frame(self):\n","        ret, frame = self.capture.read()\n","        if not ret:\n","            raise Exception(\"Could not read a frame from the webcam.\")\n","        return frame\n","\n","    def generate_filename(self, count):\n","        return f'Frame {count:02d}.jpg'\n","\n","    def record_video(self, path, duration=10):\n","        frames_dir = os.path.join(path, RECORDING_OUTPUT)\n","        os.makedirs(frames_dir, exist_ok=True)\n","        start_time = time.time()\n","        end_time = start_time + duration\n","        count = -1\n","\n","        while True:\n","            count += 1\n","            filename = os.path.join(frames_dir, self.generate_filename(count))\n","            frame = self.get_frame()\n","            cv2.imwrite(filename, frame)\n","            print(filename)\n","            cv2.imshow('Webcam Feed', frame)\n","\n","            if cv2.waitKey(1000 // FPS) & 0xFF == ord('q') or time.time() > end_time or count > 98:\n","                break\n","\n","        self.capture.release()\n","        cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mrsnyKBPDACm"},"outputs":[],"source":["class FaceExtractor:\n","    def process_frame(self, filename):\n","        try:\n","            count = os.path.split(filename)[1].split(' ')[1].split('.')[0]\n","            filename1 = os.path.join(os.path.join(DIRECTORY, RECORDING_OUTPUT), filename)\n","\n","            faces = RetinaFace.extract_faces(filename1, threshold=FACE_THRESHOLD, model=None, allow_upscaling=True)\n","\n","            if not faces:\n","                print(f\"No faces extracted in Frame {count}.\")\n","                return None\n","\n","            path0 = os.path.join(DIRECTORY, FACE_OUTPUT)\n","            if not os.path.exists(path0):\n","                os.makedirs(path0)\n","\n","            id = 1\n","\n","            image_sizes = [np.prod(image.shape) for image in faces]\n","            largest_index = np.argmax(image_sizes)\n","            filename2 = f\"user.{id}.{count}.jpg\"\n","            result = os.path.join(path0, filename2)\n","            print(f\"user.1.{count}.jpg written\")\n","            cv2.imwrite(result, faces[largest_index])\n","\n","            return count\n","\n","        except Exception as e:\n","            print(str(e))\n","            return None\n","\n","    async def video_to_faces_parallel(self):\n","        os.chdir(DIRECTORY)\n","        if os.path.exists(RECORDING_OUTPUT):\n","            files = os.listdir(os.path.join(DIRECTORY, RECORDING_OUTPUT))\n","\n","            with concurrent.futures.ThreadPoolExecutor(max_workers=FACE_MAX_WORKERS) as executor:\n","                futures = [executor.submit(self.process_frame, filename) for filename in files]\n","                concurrent.futures.wait(futures)\n","        else:\n","            print(\"No photos folder found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7kd0K72DCPm"},"outputs":[],"source":["class Cleanup:\n","    @staticmethod\n","    def clean():\n","        directory_path = os.path.join(DIRECTORY, RECORDING_OUTPUT)\n","        try:\n","            shutil.rmtree(directory_path)\n","            print(f'Directory \"{directory_path}\" and its contents have been successfully deleted.')\n","        except Exception as e:\n","            print(f'An error occurred: {e}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hCEoVRJ3DEju"},"outputs":[],"source":["class Deep:\n","    @staticmethod\n","    def represent(img_path, model_name=\"VGG-Face\", enforce_detection=False, detector_backend=\"retinaface\", align=True,\n","                  normalization=\"base\"):\n","        resp_objs = []\n","        model = dpf.build_model(model_name)\n","\n","        target_size = functions.find_target_size(model_name=model_name)\n","        if detector_backend != \"skip\":\n","            img_objs = functions.extract_faces(img=img_path, target_size=target_size, detector_backend=detector_backend,\n","                                               grayscale=False, enforce_detection=enforce_detection, align=align)\n","        else:\n","            if isinstance(img_path, str):\n","                img = functions.load_image(img_path)\n","            elif type(img_path).__module__ == np.__name__:\n","                img = img_path.copy()\n","            else:\n","                raise ValueError(f\"unexpected type for img_path - {type(img_path)}\")\n","\n","            if len(img.shape) == 4:\n","                img = img[0]\n","            if len(img.shape) == 3:\n","                img = cv2.resize(img, target_size)\n","                img = np.expand_dims(img, axis=0)\n","\n","            img_region = [0, 0, img.shape[1], img.shape[0]]\n","            img_objs = [(img, img_region, 0)]\n","\n","        for img, region, _ in img_objs:\n","            img = functions.normalize_input(img=img, normalization=normalization)\n","\n","            if \"keras\" in str(type(model)):\n","                embedding = model.predict(img, verbose=0)[0].tolist()\n","            else:\n","                embedding = model.predict(img)[0].tolist()\n","\n","            resp_obj = {\"embedding\": embedding, \"facial_area\": region}\n","            resp_objs.append(resp_obj)\n","\n","        return resp_objs\n","\n","    def create_pkl_multiprocessing(self):\n","\n","        tik = time.time()\n","\n","        db_path = FACE_OUTPUT\n","        model_name = \"VGG-Face\"\n","        enforce_detection = False\n","        detector_backend = \"retinaface\"\n","        align = True\n","        normalization = \"base\"\n","        silent = False\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","\n","        pkl = f\"{db_path}/{file_name}\"\n","\n","        if os.path.exists(pkl):\n","            os.remove(pkl)\n","\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if ((\".jpg\" in file.lower()) or (\".jpeg\" in file.lower()) or (\".png\" in file.lower())):\n","                    exact_path = os.path.join(r, file)\n","                    employees.append(exact_path)\n","\n","        if len(employees) == 0:\n","            raise ValueError(\"There is no image in \", db_path, \" folder! Validate .jpg or .png files exist in this path.\")\n","\n","        representations = []\n","\n","        with Pool(PKL_MAX_WORKERS) as pool:\n","            for batch_start in range(0, len(employees), PKL_MAX_WORKERS):\n","                batch_employees = employees[batch_start:batch_start + PKL_MAX_WORKERS]\n","                representations_list = list(tqdm(pool.imap(process_image, batch_employees), total=len(batch_employees), desc=\"Finding representations\", disable=silent))\n","                representations.extend([item for sublist in representations_list for item in sublist])\n","\n","        with open(pkl, \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(f\"Representations stored in {db_path}/{file_name}. Please delete this file when you add new identities in your database.\")\n","\n","        tok = time.time()\n","\n","        print(\"Multiprocessing: \",str(round(tok-tik)))\n","\n","    def create_pkl_nonopti(self):\n","\n","        tik = time.time()\n","\n","        db_path = FACE_OUTPUT\n","        model_name = \"VGG-Face\"\n","        enforce_detection = False\n","        detector_backend = \"retinaface\"\n","        align = True\n","        normalization = \"base\"\n","        silent = False\n","        target_size = functions.find_target_size(model_name=model_name)\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","\n","        pkl = f\"{db_path}/{file_name}\"\n","\n","\n","        if os.path.exists(pkl):\n","            os.remove(pkl)\n","\n","\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if (\n","                    (\".jpg\" in file.lower())\n","                    or (\".jpeg\" in file.lower())\n","                    or (\".png\" in file.lower())\n","                ):\n","                    exact_path = r + \"/\" + file\n","                    employees.append(exact_path)\n","\n","        if len(employees) == 0:\n","            raise ValueError(\n","                \"There is no image in \",\n","                db_path,\n","                \" folder! Validate .jpg or .png files exist in this path.\",\n","            )\n","\n","        # ------------------------\n","        # find representations for db images\n","\n","        representations = []\n","\n","        # for employee in employees:\n","        pbar = tqdm(\n","            range(0, len(employees)),\n","            desc=\"Finding representations\",\n","            disable=silent,\n","        )\n","        for index in pbar:\n","            employee = employees[index]\n","\n","            img_objs = functions.extract_faces(\n","                img=employee,\n","                target_size=target_size,\n","                detector_backend=detector_backend,\n","                grayscale=False,\n","                enforce_detection=enforce_detection,\n","                align=align,\n","            )\n","\n","            for img_content, _, _ in img_objs:\n","                embedding_obj = self.represent(\n","                    img_path=img_content,\n","                    model_name=model_name,\n","                    enforce_detection=enforce_detection,\n","                    detector_backend=\"skip\",\n","                    align=align,\n","                    normalization=normalization,\n","                )\n","\n","                img_representation = embedding_obj[0][\"embedding\"]\n","\n","                instance = []\n","                instance.append(employee)\n","                instance.append(img_representation)\n","                representations.append(instance)\n","\n","        # -------------------------------\n","\n","        with open(f\"{db_path}/{file_name}\", \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(\n","                f\"Representations stored in {db_path}/{file_name} file.\"\n","                + \"Please delete this file when you add new identities in your database.\"\n","            )\n","\n","        tok = time.time()\n","\n","        print(\"Non Optimized: \",str(round(tok-tik)))\n","\n","    def create_pkl_concurrent(self):\n","\n","        tik = time.time()\n","\n","        db_path = FACE_OUTPUT\n","        model_name = \"VGG-Face\"\n","        enforce_detection = False\n","        detector_backend = \"retinaface\"\n","        align = True\n","        normalization = \"base\"\n","        silent = False\n","        target_size = functions.find_target_size(model_name=model_name)\n","\n","        file_name = f\"representations_{model_name}.pkl\"\n","        file_name = file_name.replace(\"-\", \"_\").lower()\n","\n","        print(file_name)\n","\n","\n","        pkl = f\"{db_path}/{file_name}\"\n","\n","        if os.path.exists(pkl):\n","            os.remove(pkl)\n","\n","        print(pkl)\n","\n","        # # Create a tqdm progress bar object\n","        # progress_bar = tqdm(total=(len(os.listdir(os.path.join(DIRECTORY,FACE_OUTPUT)))), desc=\"Processing\", unit=\" items\")\n","\n","        employees = []\n","\n","        for r, _, f in os.walk(db_path):\n","            for file in f:\n","                if (\".jpg\" in file.lower()) or (\".jpeg\" in file.lower()) or (\".png\" in file.lower()):\n","                    exact_path = r + \"/\" + file\n","                    employees.append(exact_path)\n","\n","        if len(employees) == 0:\n","            raise ValueError( \"There is no image in \", db_path, \" folder! Validate .jpg or .png files exist in this path\")\n","\n","        representations = []\n","\n","        global count\n","        count = 0\n","\n","        def process_employee(employee):\n","            img_objs = functions.extract_faces( img=employee, target_size=target_size, detector_backend=detector_backend, grayscale=False, enforce_detection=enforce_detection, align=align, )\n","\n","            for img_content, _, _ in img_objs:\n","                embedding_obj = self.represent( img_path=img_content, model_name=model_name, enforce_detection=enforce_detection, detector_backend=\"skip\", align=align, normalization=normalization, )\n","\n","                img_representation = embedding_obj[0][\"embedding\"]\n","\n","                instance = []\n","                instance.append(employee)\n","                instance.append(img_representation)\n","                representations.append(instance)\n","                global count\n","                count += 1\n","                print(count)\n","                # progress_bar.update(1)\n","\n","\n","        # Create a ThreadPoolExecutor\n","        max_workers = PKL_MAX_WORKERS\n","        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n","            list(executor.map(process_employee, employees))\n","\n","        with open(f\"{db_path}/{file_name}\", \"wb\") as f:\n","            pickle.dump(representations, f)\n","\n","        if not silent:\n","            print(\n","                f\"Representations stored in {db_path}/{file_name} file.\"\n","                + \"Please delete this file when you add new identities in your database.\"\n","            )\n","\n","        # # Close the progress bar\n","        # progress_bar.close()\n","\n","        tok = time.time()\n","\n","        print(\"Concurrent Futures: \",str(round(tok-tik)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_LonlXZDJaJ"},"outputs":[],"source":["@app.get(\"/\", response_class=HTMLResponse)\n","async def home():\n","    html_content = \"\"\"\n","    <!DOCTYPE html>\n","    <html>\n","    <head>\n","        <title>Prerecording</title>\n","    </head>\n","    <body>\n","        <div class=\"center-text\">\n","            <h1>Welcome to the fastapi API</h1>\n","        </div>\n","\n","        <form method=\"GET\" action=\"/recording\">\n","            <button type=\"submit\">Let's start recording shall we?</button>\n","        </form>\n","    </body>\n","    </html>\n","    \"\"\"\n","    return HTMLResponse(content=html_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QIrqM_RQDVJx"},"outputs":[],"source":["@app.get(\"/recording\")\n","async def recording():\n","    try:\n","        recorder = WebcamRecorder()\n","        recorder.record_video(DIRECTORY)\n","        return RedirectResponse(url=\"/prefaceextraction\")\n","    except Exception as e:\n","        raise HTTPException(status_code=500, detail=str(e))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EP8LeFcMDWFB"},"outputs":[],"source":["@app.get(\"/prefaceextraction\", response_class=HTMLResponse)\n","async def prefaceextraction():\n","    html_content = \"\"\"\n","    <!DOCTYPE html>\n","    <html>\n","    <head>\n","        <title>Recording Done</title>\n","    </head>\n","    <body>\n","        <div class=\"center-text\">\n","            <h1>Face Extraction</h1>\n","        </div>\n","\n","        <form method=\"GET\" action=\"/faceextraction\">\n","            <button type=\"submit\">Let's now start the face extraction!</button>\n","        </form>\n","    </body>\n","    </html>\n","    \"\"\"\n","    return HTMLResponse(content=html_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFF7h3loDZL4"},"outputs":[],"source":["@app.get(\"/faceextraction\")\n","async def faceextraction():\n","    try:\n","        face_extractor = FaceExtractor()\n","        await face_extractor.video_to_faces_parallel()\n","\n","        cle = Cleanup()\n","        cle.clean()\n","\n","        return RedirectResponse(url=\"/prefacerep\")\n","    except Exception as e:\n","        raise HTTPException(status_code=500, detail=str(e))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DouBmWEQDaCp"},"outputs":[],"source":["@app.get(\"/prefacerep\", response_class=HTMLResponse)\n","async def prerepresentation():\n","    html_content = \"\"\"\n","    <!DOCTYPE html>\n","    <html>\n","    <head>\n","        <title>Face Extraction Done!</title>\n","    </head>\n","    <body>\n","        <div class=\"center-text\">\n","            <h1>Face Representation</h1>\n","        </div>\n","\n","        <form method=\"GET\" action=\"/facerep\">\n","            <button type=\"submit\">Let's now start the face representation!</button>\n","        </form>\n","    </body>\n","    </html>\n","    \"\"\"\n","    return HTMLResponse(content=html_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3VWyJy7Dcth"},"outputs":[],"source":["@app.get(\"/facerep\")\n","async def facerep():\n","    dp = Deep()\n","    dp.create_pkl_multiprocessing()\n","    dp.create_pkl_nonopti()\n","    dp.create_pkl_concurrent()\n","\n","    return RedirectResponse(url=\"/postfacerep\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FahljBAJDbQA"},"outputs":[],"source":["@app.get(\"/postfacerep\", response_class=HTMLResponse)\n","async def postrep():\n","    html_content = \"\"\"\n","    <!DOCTYPE html>\n","    <html>\n","    <head>\n","        <title>Face Extraction Done!</title>\n","    </head>\n","    <body>\n","        <div class=\"center-text\">\n","            <h1>Face Representation Done</h1>\n","        </div>\n","    </body>\n","    </html>\n","    \"\"\"\n","    return HTMLResponse(content=html_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0iyvurhDibh","outputId":"e078e430-1750-4a10-f265-0c7f209cf5db"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:     Will watch for changes in these directories: ['/content']\n","INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n","INFO:     Started reloader process [857] using StatReload\n"]}],"source":["if __name__ == \"__main__\":\n","    uvicorn.run(\"RecordingAPI:app\", port=8000, reload=True)"]}]}